{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Chargement des différentes librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### • Chargement des différentes librairies\n",
    "\n",
    "import sys, os #, math, time\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "from src.thot.sesh import *\n",
    "from src.thot.catch_features import *\n",
    "\n",
    "# from scipy.fft import fft\n",
    "import pywt, librosa            # type: ignore\n",
    "\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "# import seaborn as sns\n",
    "\n",
    "# from sklearn import model_selection, preprocessing as sk_p      # type: ignore\n",
    "# Supervised learning\n",
    "# from sklearn import ensemble, svm, linear_model, neighbors      # type: ignore\n",
    "# Unsupervised learning\n",
    "# from sklearn import cluster\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import VotingClassifier, GradientBoostingClassifier\n",
    "\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.model_selection import train_test_split, cross_validate # type: ignore\n",
    "# from sklearn.metrics import classification_report               # type: ignore\n",
    "\n",
    "# from keras.models import Sequential                             # type: ignore\n",
    "# from keras.callbacks import EarlyStopping                       # type: ignore\n",
    "# from keras.layers import GlobalAveragePooling1D, MaxPooling1D   # type: ignore\n",
    "# from keras.layers import ReLU, Dense, Dropout, Conv1D, Flatten  # type: ignore\n",
    "# from keras.layers import LSTM, LeakyReLU, PReLU, ConvLSTM1D\n",
    "# from keras.layers import Bidirectional, TimeDistributed, RepeatVector, Flatten\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.optimizers import AdamW, Adam            # type: ignore\n",
    "\n",
    "# from pyriemann.spatialfilters import CSP\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Déclaration de constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### • Déclaration de constantes\n",
    "\n",
    "# Fréquence d'échantillonnage - Hz (Nombre de valeur / sec)\n",
    "SAMPLE_RATE = 250\n",
    "#\n",
    "PW2 : int   = int(np.floor(np.log2(SAMPLE_RATE))) # 2 << SAMPLE_RATE // 32\n",
    "#\n",
    "NFFT : int  = 1 << PW2\n",
    "# Epoque en sec donnée en nombre d'échantillon consectutif # 4\" de données (multiple de 2)\n",
    "CHUNK : int = ceil_pow2(SAMPLE_RATE) << 0 # SAMPLE_RATE << 1 # (1 << PW2) * 4\n",
    "# Temps additionel pour étendre le domaines d'étude.\n",
    "LAG : int   = CHUNK >> 2 # SAMPLE_RATE >> 2 # -62     # Décalage du signal dû signal ~250ms\n",
    "# Taille des lots\n",
    "BATCH : int = 32\n",
    "#\n",
    "SLIDE : bool = False\n",
    "\n",
    "# Deux enregistrements bipolaires + neutre\n",
    "eeg_Chans   = ['C3', 'C4', 'Cz']\n",
    "# Liste des cannaux eeg associés aux évènement 0 et 1\n",
    "eeg_left    = [f'{c}_0' for c in eeg_Chans]\n",
    "eeg_right   = [f'{c}_1' for c in eeg_Chans]\n",
    "full_eeg    = eeg_left + eeg_right\n",
    "# Trois enregistrements musculaires\n",
    "ecg_Chans   = ['EOG:ch01', 'EOG:ch02', 'EOG:ch03']\n",
    "# Liste de tous les cannaux des dataframes\n",
    "all_chans   = eeg_Chans + ecg_Chans\n",
    "# Correspondance pour la classification\n",
    "hands_event = {0: 'Left', 1: 'Right'}\n",
    "# Nombre dévènement à prédire\n",
    "numbers     = range(len(hands_event))\n",
    "# Les bandes de fréquences d'intérêt\n",
    "eeg_bands   = {'Delta' : (.1, 4),\n",
    "               'Theta' : (4, 8),\n",
    "               'Alpha' : (8, 14),\n",
    "               'Beta'  : (14, 31),\n",
    "               'Gamma' : (31, (SAMPLE_RATE >> 2) - 1),}\n",
    "# Coefficients pour filtres Butterworth numérique d'ordre N pour le filtrage passe-bande\n",
    "bands_coeff = {band : butter_bandpass(low, high, SAMPLE_RATE) for band, (low, high) in eeg_bands.items()}\n",
    "# Largeur de bande retenue pour étude de cas\n",
    "band_interest = butter_bandpass(1e-3, eeg_bands['Alpha'][1], SAMPLE_RATE)\n",
    "\n",
    "LAG, CHUNK, (CHUNK if SLIDE else (CHUNK - LAG))   #, *band_interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Acquisition des données d'entrainement et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Acquisition des données d'entrainement\n",
    "path     = '../data/data.zip'\n",
    "datas    = Graphein_DatasLoader(path, 'train', True)\n",
    "files    = datas.files\n",
    "entrants = datas.runs\n",
    "targets  = datas.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Acquisition des données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = csv_in_zip(path, directory = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Test de classification - Proposition 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://raphaelvallat.com/bandpower.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Test prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### • Visualisation des spectrogrammes / Test\n",
    "\n",
    "def logMelSpectrogram(data : Vector, rate : int, dt : float = 1e-2) -> Vector :\n",
    "    tps = 1 << int(np.floor(np.log2(rate * dt)))\n",
    "    # print(tps)\n",
    "    # Spectrogramme\n",
    "    stfts = np.abs(librosa.stft(y = data, n_fft = tps, hop_length = 1 << 2, center = True)).T\n",
    "    # Filtre de MEL\n",
    "    liny  = librosa.filters.mel(sr = rate, n_fft = tps + 1, n_mels = stfts.shape[-1]).T\n",
    "    # Application du filtre au spectrogramme\n",
    "    mel_  = np.tensordot(stfts, liny, 1)\n",
    "\n",
    "    return np.log(mel_ + 1e-6)\n",
    "\n",
    "def img_spectrogram(raw : Vector, rate : int, nfft : int = 1 << 10) -> Vector :\n",
    "    return librosa.feature.melspectrogram(y = raw, sr = rate, hop_length = 1, \n",
    "                            n_fft = nfft, n_mels = 32, fmin = 0, fmax = 20, win_length = 32)\n",
    "\n",
    "def spectrogram_dep(data : Board, rate : int, channels : Clause, n_row : int = 5, n_col : int = 12) :\n",
    "    sample = np.random.default_rng().integers(data.shape[0], size = n_row)\n",
    "\n",
    "    sample.sort()\n",
    "\n",
    "    plt.figure(figsize = (18, 2 * .48 * n_row))\n",
    "\n",
    "    pos = 0\n",
    "\n",
    "    for k in sample :\n",
    "        for c in channels :\n",
    "            # x   = normalized(data[c][k])\n",
    "            raw = img_spectrogram(raw = data[c][k], rate = rate)\n",
    "            pos += 1\n",
    "            \n",
    "            plt.subplot(n_row, n_col, pos)\n",
    "            plt.title(f\"{((pos - 1) // 3) + 1} . {k} - {c}\", fontsize = 8)\n",
    "            librosa.display.specshow(data = 1 - raw, sr = rate, hop_length = 1)\n",
    "            \n",
    "            # pos = n_col * (i >> 1) + j\n",
    "            # f, t, Sxx = signal.spectrogram(x, rate)\n",
    "            # plt.subplot(n_row, n_col, pos + 4)\n",
    "            # plt.pcolormesh(t, f, 1 - Sxx, shading = 'gouraud')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show();\n",
    "\n",
    "def spectrogram(data : Board, rate : int, channels : Clause, n_row : int = 5, n_col : int = 12) :\n",
    "    sample = np.random.default_rng().integers(data.shape[0], size = n_row)\n",
    "\n",
    "    sample.sort()\n",
    "\n",
    "    plt.figure(figsize = (18, 2 * .48 * n_row))\n",
    "\n",
    "    freq = np.arange(1, rate >> 1)\n",
    "    pos  = 0\n",
    "    # extd = np.append([0, 1, 1], freq[-1])\n",
    "    \n",
    "    for k in sample :\n",
    "        for c in channels :\n",
    "            pos += 1\n",
    "            x   = normalized(data[c][k])\n",
    "            coefficients, _ = pywt.cwt(x, scales = freq, wavelet = 'cmor')\n",
    "\n",
    "            plt.subplot(n_row, n_col, pos)\n",
    "            plt.imshow(np.abs(coefficients), aspect = 'auto', cmap = 'jet') #, extent = extd\n",
    "            # plt.colorbar(label=\"Magnitude\")\n",
    "            # plt.ylabel(\"Scale\")\n",
    "            # plt.xlabel(\"Time\")\n",
    "            # plt.title(\"CWT of a Chirp Signal\")\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_logMelSpectrogram(data, rate) :\n",
    "    sns.heatmap(np.rot90(logMelSpectrogram(data, rate)), cmap = 'inferno')\n",
    "    \n",
    "    # loc, _ = plt.xticks()\n",
    "    # l      = np.round((loc - loc.min()) * len(data) / fe / loc.max(), 2), vmin = -6\n",
    "\n",
    "    # plt.xticks(loc, l)\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency (Mel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = [list(harmonic(x, bands_coeff).values()) for x in [df_trains[c] for c in eeg_Chans]]\n",
    "\n",
    "np.shape(H), np.shape(np.stack(np.stack(H, axis = 1), axis = 2)), np.shape(H[0][1][0])\n",
    "# harmonic(trains['C3'][256], bands_coeff).values())), H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_trains.drop(columns = ['EventType']),\n",
    "                                                    df_trains['EventType'], test_size = .2, random_state = 42)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split([v.tolist() for v in np.array(trains[eeg_Channels])],\n",
    "#                                                     trains['EventType'], test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = np.array(X_train)\n",
    "# test_dataset  = X_test\n",
    "\n",
    "# train_dataset = structure(X_train, SAMPLE_RATE, eeg_Chans[:2])\n",
    "# test_dataset  = structure(X_test, SAMPLE_RATE, eeg_Chans[:2])\n",
    "\n",
    "# train_dataset = structure(X_train, SAMPLE_RATE, eeg_Chans[: 2])\n",
    "# test_dataset  = structure(X_test, SAMPLE_RATE, eeg_Chans[: 2])\n",
    "\n",
    "train_dataset = structure(df_trains.drop(columns = ['EventType']), SAMPLE_RATE, eeg_Chans[: 2])\n",
    "test_dataset  = structure(df_test.drop(columns = ['EventType']), SAMPLE_RATE, eeg_Chans[: 2])\n",
    "\n",
    "# print(train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_dataset)\n",
    "\n",
    "sum([np.where(x > .5)[0][0] for x in pred] == y_test) / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "loss_values  = history_dict['loss']\n",
    "acc_values   = history_dict['accuracy']\n",
    "absc         = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.figure(figsize = (12, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(absc, loss_values, label = 'Loss')\n",
    "plt.plot(absc, acc_values, label = 'Accuracy')\n",
    "plt.title('Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(absc, history_dict['val_loss'], label = 'Loss')\n",
    "plt.plot(absc, history_dict['val_accuracy'], label = 'Accuracy')\n",
    "plt.title('Testing')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Visualisation densité spectrale du Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### • Visualisation Densité Spectral du Signal\n",
    "\n",
    "plot_psd(entrants, train_runs, rate = SAMPLE_RATE, Channels = eeg_Chans, titled = headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Densité spectrale / échantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### • Densité spectral / échantillon\n",
    "\n",
    "inc   = 40\n",
    "scp = samples(train_samples, inc)\n",
    "boolInt = -2\n",
    "\n",
    "plt.figure(figsize = (15, inc * 1.5))\n",
    "\n",
    "for i in scp :\n",
    "    boolInt += 2\n",
    "\n",
    "    for c in eeg_Chans :\n",
    "        y = train_runs[0][c][i]\n",
    "        yest, Pxx_den = signal.welch(y, SAMPLE_RATE)   # , scaling = 'spectrum'\n",
    "        \n",
    "        plt.subplot(inc, 4, boolInt + 1)\n",
    "        plt.semilogy(yest, Pxx_den, label = c)\n",
    "        plt.title(f\"welch - {i + 1}\", fontsize = 11)\n",
    "        plt.grid()\n",
    "\n",
    "        plt.subplot(inc, 4, boolInt + 2)\n",
    "        res, _ = plt.psd(y, Fs = SAMPLE_RATE, label = c) # , NFFT = NFFT\n",
    "        plt.title(f\"psd - {i + 1}\", fontsize = 11)\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('')\n",
    "        # plt.legend()\n",
    "\n",
    "plt.xlabel('frequency [Hz]')\n",
    "# plt.ylabel('PSD [V**2/Hz]')\n",
    "plt.tight_layout()\n",
    "plt.show();\n",
    "\n",
    "# f, Pxx_den = signal.welch(train_eras[0]['C3'][752], SAMPLE_RATE)\n",
    "\n",
    "# print(len(Pxx_den))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Visualisation Epoques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### • Visualisation Epoques\n",
    "\n",
    "for i in range(len(files))[:: 3] :\n",
    "    plot_signal(entrants[i], parts[i], train_spots[0][i], train_spots[1][i], channels = eeg_Chans, # \n",
    "                period = CHUNK, lag = LAG, title = headers[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Visualisation décomposition des signaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### • Visualisation Décomposition des signaux\n",
    "\n",
    "# Test de décomposition des signaux en bandes de fréquences spécifiques compatibles avec les répartitions usuelles\n",
    "# dans le domaine des EEG ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']\n",
    "\n",
    "for input, token in zip(train_runs, ['Gauche', 'Droite']) :\n",
    "    print(f\"Exemples - Évènement Discriminé Main {token}\")\n",
    "    plot_wavelets(input, bands_coeff, eeg_Chans, scope = 30, headers = headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Visualisation des spectrogrammes (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in zip(numbers, ['Gauche', 'Droite']) :\n",
    "    print(f\"Exemples - Évènement Discriminé Main {t}\")\n",
    "    spectrogram(train_runs[i], SAMPLE_RATE, eeg_Chans, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • MNE époque (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### • MNE époque (test)\n",
    "\n",
    "raw_csv = entrants[0][eeg_Chans]\n",
    "info    = mne.create_info(ch_names = eeg_Chans, sfreq = SAMPLE_RATE, ch_types = 'eeg')\n",
    "raw_mne = mne.io.RawArray(raw_csv.T * 1e-6, info)\n",
    "sites     = np.where(entrants[0]['EventStart'] == 1)[0]\n",
    "\n",
    "# display(compare(np.sort(np.concatenate((train_spots[0][0], train_spots[1][0]))), loc))\n",
    "\n",
    "tmin, tmax = -0., 1\n",
    "\n",
    "# loc = mne.find_events(raw_mne, stim_channel = 'C3')\n",
    "# event_id = dict(C3 = 1, aud_r = 2, vis_l = 3, vis_r = 4)\n",
    "# raw = mne.io.Raw(raw_mne, preload = True)\n",
    "# raw.filter(2, None, method = 'iir')           # replace baselining with high-pass\n",
    "# events = mne.read_events(event_fname)\n",
    "\n",
    "# raw.info['bads'] = ['MEG 2443']  # set bad channels\n",
    "# picks = mne.pick_types(info, meg = 'grad', eeg = True, eog = False, exclude = 'bads')\n",
    "# Read epochs\n",
    "absc = mne.Epochs(raw_mne, np.array([sites, sites, sites]).T, None, tmin, tmax, proj = False,\n",
    "                    picks = None, baseline = None, preload = True, verbose = False) # event_id picks\n",
    "\n",
    "# labels = epochs.events[::5, -1]\n",
    "\n",
    "# events\n",
    "\n",
    "# raw_mne.plot();\n",
    "\n",
    "# raw_mne['C3'][0][0], len(df_train_csv[2]['Cz'])\n",
    "\n",
    "display(absc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Test de classification - Proposition 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, y = bands_coeff['Theta']\n",
    "\n",
    "i = np.random.randint(np.shape(X)[0])\n",
    "y = df_trains['C4'][i] - df_trains['C3'][i]\n",
    "# X = [np.sign(s) for s in (trains['C4'] - trains['C3'])]\n",
    "# y = {band: bandpass_filter(X[i], b, a) for band, (b, a) in bands_coeff.items()}\n",
    "\n",
    "plt.figure()\n",
    "# plt.style.use('')\n",
    "\n",
    "plt.plot(normalized(bandpass_filter(y, b, y)), label = 'C4 - C3')\n",
    "plt.plot(normalized(bandpass_filter(np.sign(y), b, y)), label = '[C4 - C3]', c = np.random.rand(1, 3)[0])\n",
    "# plt.plot(pywt.dwt(y, wavelet = 'db4')[0], label = 'C4 - C3')\n",
    "# plt.plot(pywt.dwt(np.sign(y), wavelet = 'db4')[0], label = '[C4 - C3]')\n",
    "# plt.plot(np.zeros(512), ls = '--', c = np.random.rand(1, 3)[0])\n",
    "\n",
    "# print(np.shape(pywt.dwt(y, wavelet = 'db8')))\n",
    "\n",
    "# plt.plot(bandpass_filter(np.sign(trains['C3'][i]), b, a), label = 'C3')\n",
    "# plt.plot(bandpass_filter(np.sign(trains['C4'][i]), b, a), label = 'C4')\n",
    "# plt.plot(bandpass_filter(np.sign(trains['Cz'][i]), b, a), label = 'Cz')\n",
    "\n",
    "# for (band, signal) in reversed(y.items()) :\n",
    "#     plt.plot(pd.Series(signal), label = f'{band}', c = np.random.rand(1, 3)[0])\n",
    "\n",
    "plt.title(f\"{i}\")\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    ## K-plus proches voisins\n",
    "    'knn__n_neighbors' : range(2),\n",
    "    ## SVM\n",
    "    'svm__C'      : [0.1, 1, 5],\n",
    "    'svm__kernel' : ['linear', 'softmax', 'sigmoid', 'rbf'],\n",
    "    ## RandomForest\n",
    "    # 'rf__max_features'      : ['sqrt', 'log2', None],\n",
    "    # 'rf__min_samples_split' : range(2, 32, 2),\n",
    "    # , ('rf', clf3), ('rf', clf3)\n",
    "    'estimators': [[('knn', knc), ('svm', svm)], [('knn', knc), ('svm', svm)]] \n",
    "    }\n",
    "\n",
    "grid = model_selection.GridSearchCV(estimator = Voting_clf, param_grid = params, cv = 5) \\\n",
    "    .fit(X_train_scaled, y_train)\n",
    "\n",
    "# parametres = {'max_features' : ['log2', 'sqrt', None], 'min_samples_split' : range(2, 32, 2)}\n",
    "\n",
    "# vclf = model_selection.GridSearchCV(estimator = clf3, param_grid = parametres, cv = 3) \\\n",
    "#     .fit(X_train_scaled, y_train)\n",
    "\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "print('score train :', grid.score(X_train_scaled, y_train))\n",
    "print('score test :', grid.score(X_test_scaled, y_test))\n",
    "\n",
    "# print(vclf.best_estimator_, vclf.best_params_, vclf.best_score_)\n",
    "# print('score train :', grid.score(X_train_scaled, y_train), vclf.score(X_train_scaled, y_train))\n",
    "# print('score test  :', grid.score(X_test_scaled, y_test), vclf.score(X_test_scaled, y_test))\n",
    "\n",
    "df_train_cpy, event_start = fancy_df(entrants, targets['EventType'], hands_event, CHUNK)\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize = (24, 5), sharey = True)\n",
    "sig = .05\n",
    "\n",
    "axes.plot(entrants['C3'])\n",
    "\n",
    "for p in event_start :\n",
    "    axes.axvspan(p[0] - (CHUNK >> 1), p[0] + 1.5 * CHUNK, facecolor = 'orangered', alpha = .5)\n",
    "\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolInt = 16\n",
    "start   = event_start[boolInt][0]\n",
    "entrant = start + CHUNK\n",
    "input   = df_train_cpy['C3_4'][start : entrant]\n",
    "smooth  = input.copy()\n",
    "inc     = 5\n",
    "alpha   = 1 / 3\n",
    "dec     = int(inc / alpha)\n",
    "\n",
    "plt.figure(figsize = (24, 5))\n",
    "plot_window(entrants, ['C3', 'C4', 'C3 + C4'], start, CHUNK)\n",
    "\n",
    "# Lissage des hautes fréquences\n",
    "for _ in range(inc) :\n",
    "    smooth = simple_exponential_smoothing(smooth, alpha, 0)\n",
    "\n",
    "smooth = pd.Series(index = range(start, entrant + inc - dec), data = smooth[dec :])\n",
    "\n",
    "# plt.plot(raw - smooth, label = hands[event_start[pos][1]])\n",
    "plt.plot(smooth, '--', label = hands_event[event_start[boolInt][1]])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Apendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"text-align:center\" ><b>EEG</b> - Prédiction des Mouvements Imaginaires de la Main</h2>\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. Le projet**\n",
    "- Intoduction  \n",
    "https://github.com/DataScientest-Studio/mar24_cds_eeg/blob/eric/references/Description_projet_EEG.pdf  \n",
    "https://www.bbci.de/competition/iv/desc_2b.pdf\n",
    "- Ressources / Données   \n",
    "https://www.kaggle.com/competitions/ucsd-neural-data-challenge/overview  \n",
    "- Bibliographie  \n",
    "https://www.bbci.de/competition/iv/desc_2b.pdf\n",
    "#### **2. Liens utils**\n",
    "- SciPy - *open-source software for mathematics, science, and engineering*  \n",
    "https://docs.scipy.org/doc/scipy/index.html  \n",
    "https://docs.scipy.org/doc/scipy/reference/signal.html  \n",
    "- MNE - *MEG + EEG Analysis & Visualisation*\n",
    "   - Accueil  \n",
    "   https://mne.tools/stable/index.html\n",
    "\n",
    "   - MNE - Data structures from arbitrary data  \n",
    "   https://mne.tools/stable/auto_tutorials/io/10_reading_meg_data.html#creating-mne-data-structures-from-arbitrary-data-from-memory\n",
    "   \n",
    "   - MNE - EEG Preprocessing  \n",
    "   https://mne.tools/dev/auto_tutorials/preprocessing/index.html  \n",
    "\n",
    "- pyRiemann - *Biosignals classification with Riemannian geometry*  \n",
    "https://pyriemann.readthedocs.io/en/latest/  \n",
    "- neurodsp - *Neuro Digital Signal Processing Toolbox*  \n",
    "https://neurodsp-tools.github.io/neurodsp/index.html#\n",
    "- Rythme Mu  \n",
    "https://fr.wikipedia.org/wiki/Rythme_Mu\n",
    "- Spectrogram from EEG  \n",
    "https://www.kaggle.com/code/cdeotte/how-to-make-spectrogram-from-eeg\n",
    "- Divers  \n",
    "https://signalprocessingsociety.org/  \n",
    "https://fr.wikipedia.org/wiki/Filtre_de_Butterworth  \n",
    "https://fr.wikipedia.org/wiki/Moyenne_mobile  \n",
    "https://terpconnect.umd.edu/~toh/spectrum/Differentiation.html  \n",
    "https://perso.etis-lab.fr/ghaffari/2014_CCMB_Floride_USA.pdf  \n",
    "https://www.youtube.com/watch?v=wB417SAbdak&list=PLXc9qfVbMMN2TAoLHVW5NvNmJtwiHurzw  \n",
    "https://fastercapital.com/fr/sujet/identification-des-artefacts-de-traitement-du-signal-dans-des-sc%C3%A9narios-r%C3%A9els.html#:~:text=L'inspection%20visuelle%20est%20la,des%20pertes%20et%20du%20bruit.  \n",
    "   - Z-Score Normalisation  \n",
    "   https://fr.wikipedia.org/wiki/Cote_Z_(statistiques)  \n",
    "   https://typeset.io/questions/why-is-z-score-normalisation-necessary-in-pre-processing-eeg-1xv5jepyq5  \n",
    "\n",
    "   - Traitement numérique du signal  \n",
    "   https://fr.wikipedia.org/wiki/Traitement_num%C3%A9rique_du_signal  \n",
    "   - Ondelette  \n",
    "      - Wiki  \n",
    "      https://fr.wikipedia.org/wiki/Ondelette  \n",
    "\n",
    "      - L’analyse par ondelettes dans la vie de tous les jours  \n",
    "      https://interstices.info/lanalyse-par-ondelettes-dans-la-vie-de-tous-les-jours/  \n",
    "\n",
    "      - A guide for using the Wavelet Transform in Machine Learning  \n",
    "      https://ataspinar.com/2018/12/21/a-guide-for-using-the-wavelet-transform-in-machine-learning/\n",
    "      \n",
    "      - pyWavelets - *open source wavelet transform*  \n",
    "      https://pywavelets.readthedocs.io/en/latest/\n",
    "\n",
    "      - Ondelettes et applications  \n",
    "      https://www.i2m.univ-amu.fr/~caroline.chaux/GEOMDATA/TI-te5215.pdf\n",
    "\n",
    "   - Maximum de vraisemblance  \n",
    "   https://pmarchand1.github.io/ECL8202/notes_cours/03-Maximum_vraisemblance.html  \n",
    "   https://fr.wikipedia.org/wiki/Maximum_de_vraisemblance#:~:text=En%20statistique%2C%20l'estimateur%20du,maximisant%20la%20fonction%20de%20vraisemblance  \n",
    "\n",
    "   - Transformation de Fourier discrète  \n",
    "   https://fr.wikipedia.org/wiki/Transformation_de_Fourier_discr%C3%A8te  \n",
    "      - La Transformation de Fourier n’est pas adaptée à l’analyse des signaux non stationnaires.\n",
    "   - Neural Data Science in Python  \n",
    "   https://neuraldatascience.io/intro.html\n",
    "\n",
    "   - Preprocessing of EEG  \n",
    "   https://www.frontiersin.org/articles/10.3389/fninf.2015.00016/full#:~:text=The%20depositable%20preprocessing%20pipeline%20consists,with%20a%20low%20recording%20SNR  \n",
    "   https://typeset.io/papers/preprocessing-of-eeg-4go8vhcbty  \n",
    "   https://learn.neurotechedu.com/preprocessing  \n",
    "   https://g0rella.github.io/gorella_mwn/preprocessing_eeg.html  \n",
    "   \n",
    "   - Biblio :  \n",
    "   https://perso.telecom-paristech.fr/bloch/P6Image/ondelettestrsp.pdf  \n",
    "   https://www.math.u-bordeaux.fr/~jbigot/Site/Enseignement_files/ondelettesIMAT.pdf  \n",
    "   http://w3.cran.univ-lorraine.fr/perso/radu.ranta/pdf/cours_deb_ond%28fr%29.pdf\n",
    "   \n",
    "   - Digital Filtering  \n",
    "   http://notebooks.pluxbiosignals.com/notebooks/Categories/Pre-Process/digital_filtering_eeg_rev.html\n",
    "\n",
    "   - Processus stationnaire  \n",
    "   https://fr.wikipedia.org/wiki/Processus_stationnaire\n",
    "\n",
    "   - Analyse en composantes principales  \n",
    "   https://fr.wikipedia.org/wiki/Analyse_en_composantes_principales#:~:text=L'ACP%2C%20d%C3%A9sign%C3%A9e%20en%20g%C3%A9n%C3%A9ral,une%20grandeur%20physique%2C%20comme%20les"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
