{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"text-align:center\" ><b>EEG</b> - Prédiction des Mouvements Imaginaires de la Main</h2>\n",
    "\n",
    "---\n",
    "\n",
    "# **1. Description du projet**\n",
    "- Introduction :  \n",
    "L’électroencéphalogramme (EEG) est une technique d’imagerie cérébrale utilisée pour étudier les activités du cerveau.  \n",
    "En plaçant des capteurs sur le cuir chevelu, l’activité électrique du cerveau est enregistrée, ce qui permet de comprendre les fonctionnements cérébraux et d’identifier certains schémas que l’on peut ensuite attribuer à des comportements précis.  \n",
    "Un des schémas d'EEG qui a été beaucoup étudié est l’imagerie motrice (IM), ou le mouvement imaginaire de la main.  \n",
    "Les IM créent des schémas bien définis qui peuvent être détectés.  \n",
    "Le but de ce projet est de créer et d’entraîner un programme permettant de prédire si l’IM d’une personne correspond à un mouvement de la main droite ou de la main gauche.  \n",
    "# **2. Étapes du projet**\n",
    "- Prétraitement des Données :  \n",
    "Les données EEG sont sujettes à des artefacts ou des erreurs de collecte dues à des mouvements parasites ou des interférences.  \n",
    "Il est donc nécessaire d'appliquer un système de prétraitement des données pour réduire le bruit et extraire les bandes de fréquences pertinentes.\n",
    "\n",
    "- Segmentation des données et extraction des caractéristiques :  \n",
    "Les données EEG sont présentées comme un flux continu. Il est donc important, pour une meilleure analyse, de diviser les données en segments temporels correspondant à l’IM.  \n",
    "Ensuite, identifier et extraire les caractéristiques pertinentes des signaux EEG associées aux IM est essentiel.  \n",
    "Cela comprend la puissance et d'autres spécificités de l’activité électrique qui définissent les IM.\n",
    "\n",
    "- Analyse statistique exploratoire :  \n",
    "Utiliser les outils d’analyse exploratoire pour mieux comprendre les données et identifier les tendances ou les patterns significatifs.\n",
    "\n",
    "- Entraînement du modèle :  \n",
    "Entraîner un modèle permettant de distinguer les différences entre les IM des mains droite et gauche.  \n",
    "Optimiser le modèle et évaluer sa performance sur un ensemble de test.\n",
    "\n",
    "- Conclusion :  \n",
    "Ces étapes sont cruciales pour développer un programme efficace de prédiction des mouvements imaginaires de la main basé sur les données EEG.\n",
    "# **3. Ressources**\n",
    "- Données   \n",
    "https://www.kaggle.com/competitions/ucsd-neural-data-challenge/overview  \n",
    "- Bibliographie  \n",
    "https://www.bbci.de/competition/iv/desc_2b.pdf\n",
    "# **4. Liens utils**\n",
    "- SciPy - *open-source software for mathematics, science, and engineering*  \n",
    "https://docs.scipy.org/doc/scipy/index.html  \n",
    "https://docs.scipy.org/doc/scipy/reference/signal.html  \n",
    "- MNE - *MEG + EEG Analysis & Visualisation*\n",
    "   - Accueil  \n",
    "   https://mne.tools/stable/index.html\n",
    "\n",
    "   - MNE - Data structures from arbitrary data  \n",
    "   https://mne.tools/stable/auto_tutorials/io/10_reading_meg_data.html#creating-mne-data-structures-from-arbitrary-data-from-memory\n",
    "   \n",
    "   - MNE - EEG Preprocessing  \n",
    "   https://mne.tools/dev/auto_tutorials/preprocessing/index.html  \n",
    "\n",
    "- pyRiemann - *Biosignals classification with Riemannian geometry*  \n",
    "https://pyriemann.readthedocs.io/en/latest/  \n",
    "- neurodsp - *Neuro Digital Signal Processing Toolbox*  \n",
    "https://neurodsp-tools.github.io/neurodsp/index.html#\n",
    "- Rythme Mu  \n",
    "https://fr.wikipedia.org/wiki/Rythme_Mu\n",
    "- Divers  \n",
    "https://signalprocessingsociety.org/  \n",
    "https://fr.wikipedia.org/wiki/Filtre_de_Butterworth  \n",
    "https://fr.wikipedia.org/wiki/Moyenne_mobile  \n",
    "https://terpconnect.umd.edu/~toh/spectrum/Differentiation.html  \n",
    "https://perso.etis-lab.fr/ghaffari/2014_CCMB_Floride_USA.pdf  \n",
    "https://www.youtube.com/watch?v=wB417SAbdak&list=PLXc9qfVbMMN2TAoLHVW5NvNmJtwiHurzw  \n",
    "https://fastercapital.com/fr/sujet/identification-des-artefacts-de-traitement-du-signal-dans-des-sc%C3%A9narios-r%C3%A9els.html#:~:text=L'inspection%20visuelle%20est%20la,des%20pertes%20et%20du%20bruit.  \n",
    "   - Z-Score Normalisation  \n",
    "   https://fr.wikipedia.org/wiki/Cote_Z_(statistiques)  \n",
    "   https://typeset.io/questions/why-is-z-score-normalisation-necessary-in-pre-processing-eeg-1xv5jepyq5  \n",
    "\n",
    "   - Traitement numérique du signal  \n",
    "   https://fr.wikipedia.org/wiki/Traitement_num%C3%A9rique_du_signal  \n",
    "   - Ondelette  \n",
    "      - Wiki  \n",
    "      https://fr.wikipedia.org/wiki/Ondelette  \n",
    "\n",
    "      - L’analyse par ondelettes dans la vie de tous les jours  \n",
    "      https://interstices.info/lanalyse-par-ondelettes-dans-la-vie-de-tous-les-jours/  \n",
    "\n",
    "      - A guide for using the Wavelet Transform in Machine Learning  \n",
    "      https://ataspinar.com/2018/12/21/a-guide-for-using-the-wavelet-transform-in-machine-learning/\n",
    "      \n",
    "      - pyWavelets - *open source wavelet transform*  \n",
    "      https://pywavelets.readthedocs.io/en/latest/\n",
    "\n",
    "      - Ondelettes et applications  \n",
    "      https://www.i2m.univ-amu.fr/~caroline.chaux/GEOMDATA/TI-te5215.pdf\n",
    "\n",
    "   - Maximum de vraisemblance  \n",
    "   https://pmarchand1.github.io/ECL8202/notes_cours/03-Maximum_vraisemblance.html  \n",
    "   https://fr.wikipedia.org/wiki/Maximum_de_vraisemblance#:~:text=En%20statistique%2C%20l'estimateur%20du,maximisant%20la%20fonction%20de%20vraisemblance  \n",
    "\n",
    "   - Transformation de Fourier discrète  \n",
    "   https://fr.wikipedia.org/wiki/Transformation_de_Fourier_discr%C3%A8te  \n",
    "      - La Transformation de Fourier n’est pas adaptée à l’analyse des signaux non stationnaires.\n",
    "   - Neural Data Science in Python  \n",
    "   https://neuraldatascience.io/intro.html\n",
    "\n",
    "   - Preprocessing of EEG  \n",
    "   https://www.frontiersin.org/articles/10.3389/fninf.2015.00016/full#:~:text=The%20depositable%20preprocessing%20pipeline%20consists,with%20a%20low%20recording%20SNR  \n",
    "   https://typeset.io/papers/preprocessing-of-eeg-4go8vhcbty  \n",
    "   https://learn.neurotechedu.com/preprocessing  \n",
    "   https://g0rella.github.io/gorella_mwn/preprocessing_eeg.html  \n",
    "   \n",
    "   - Biblio :  \n",
    "   https://perso.telecom-paristech.fr/bloch/P6Image/ondelettestrsp.pdf  \n",
    "   https://www.math.u-bordeaux.fr/~jbigot/Site/Enseignement_files/ondelettesIMAT.pdf  \n",
    "   http://w3.cran.univ-lorraine.fr/perso/radu.ranta/pdf/cours_deb_ond%28fr%29.pdf\n",
    "   \n",
    "   - Digital Filtering  \n",
    "   http://notebooks.pluxbiosignals.com/notebooks/Categories/Pre-Process/digital_filtering_eeg_rev.html\n",
    "\n",
    "   - Processus stationnaire  \n",
    "   https://fr.wikipedia.org/wiki/Processus_stationnaire\n",
    "\n",
    "   - Analyse en composantes principales  \n",
    "   https://fr.wikipedia.org/wiki/Analyse_en_composantes_principales#:~:text=L'ACP%2C%20d%C3%A9sign%C3%A9e%20en%20g%C3%A9n%C3%A9ral,une%20grandeur%20physique%2C%20comme%20les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "import mne\n",
    "\n",
    "# from scipy.fft import fft  #, stats, fft, fftfreq\n",
    "# from sktime import pycatch22\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn import preprocessing, model_selection, ensemble, svm, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sktime.transformations.panel.catch22 import Catch22 as c22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Deprecated\n",
    "\n",
    "### Ce DataFrame sera utilisé pour l'étude de des signaux.\n",
    "# @deprecated(\"Plus utilisé dans le cadre de ce projet\")\n",
    "def fancy_df(df : pd.DataFrame, events : list, hands : dict, size : int,\n",
    "             expend : int = 0) -> tuple[pd.DataFrame, list] : # deprecated\n",
    "    df_cpy = pd.DataFrame({'C3_4'  : df[['C3', 'C4']].sum(axis = 1), # Somme des signaux 'C3' et 'C4'.\n",
    "                            # 'EventStart' : df['EventStart'],       # Survenue d'un évènement lié à une des mains.\n",
    "                           'Hand'  : 0,                              # Activité liée à l'une des mains.\n",
    "                           'Left'  : 0,                              # Activité liée à la main gauche.\n",
    "                           'Right' : 0})                             # Activité liée à la main droite.\n",
    "    evts  = list(zip(np.where(df['EventStart'] == 1)[0], events))\n",
    "    size += 2 * expend\n",
    "    # df_cpy['zCore'] = stats.zscore(df['C3_4'])\n",
    "\n",
    "    for i, j in evts :\n",
    "        i                        -= expend\n",
    "        fin                       = range(i, i + size)\n",
    "        df_cpy.loc[fin, 'Hand']   = np.ones(size)\n",
    "        df_cpy.loc[fin, hands[j]] = np.ones(size)\n",
    "\n",
    "    return df_cpy, evts # [i[0] for i in evts]\n",
    "\n",
    "### \n",
    "# @deprecated(\"Plus utilisé dans le cadre de ce projet\")\n",
    "def left_right_old(df : pd.DataFrame, events : list, size : int, canals, hand : int = 0,\n",
    "                      expend : int = 0) -> pd.DataFrame :\n",
    "    lp    = range(len(canals))\n",
    "    res   = [[] for _ in lp]\n",
    "    size += expend * 2\n",
    "\n",
    "    for i in events :\n",
    "        i   -= expend\n",
    "        fin = range(i, i + size)\n",
    "\n",
    "        for k, c in enumerate(canals) :\n",
    "            res[k] = np.append(res[k], df.loc[fin, c].values)\n",
    "\n",
    "    return pd.DataFrame({'signal_epoched' : res, 'canal' : canals, 'hand' : hand, 'data_split' : [events for _ in lp]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "### Décorateur : Temps d'exécution d'une fonction\n",
    "def temps_execution(function : any) -> any:\n",
    "    def timer(*args, **kwargs) :\n",
    "        debut = time.time()\n",
    "        # ------------------------------------------\n",
    "        results = function(*args, **kwargs)\n",
    "        \n",
    "        print(f\"Fonction exécutée en {time.time() - debut} s\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    return timer\n",
    "\n",
    "### https://pandas.pydata.org/docs/reference/io.html\n",
    "def pickle_in_zip(fichier_zip : str, fichier_specifique : str) -> pd.DataFrame :\n",
    "    with ZipFile(fichier_zip).open(fichier_specifique) as f :\n",
    "        return pd.read_pickle(f)\n",
    "\n",
    "### https://pandas.pydata.org/docs/reference/io.html\n",
    "def csv_in_zip(compressed_files : str, directory : str = None, files : list[str] | str = None) \\\n",
    "        -> list[pd.DataFrame] :\n",
    "    res = []\n",
    "    dir = '' if ((directory is None) | (directory == '')) else (directory + '/')\n",
    "\n",
    "    with ZipFile(compressed_files) as myzip :\n",
    "        filters = myzip.infolist() if dir == '' else \\\n",
    "                  [fic for fic in myzip.infolist() if dir in fic.filename]\n",
    "\n",
    "        if files != None :\n",
    "            records = [dir + X for X in files]\n",
    "            filters = [X for X in filters if (X.filename in records)]\n",
    "\n",
    "        for fic in filters :\n",
    "            with myzip.open(fic.filename) as f :\n",
    "                res.append(pd.read_csv(f, encoding_errors = 'ignore'))\n",
    "\n",
    "    return res\n",
    "\n",
    "### \n",
    "def hand_out(df : pd.DataFrame, events : list[int], width : int, channels : list[str],\n",
    "             hand : int = 0, expend : int = 0) -> pd.DataFrame :\n",
    "    extra  = pd.DataFrame()\n",
    "    width  += 2 * expend\n",
    "    signal = [f'S_{i}' for i in range(width)]\n",
    "    \n",
    "    for i in events :\n",
    "        i   -= expend\n",
    "        span = range(i, i + width)\n",
    "        part = [{**{'data_split' : i},\n",
    "                 **dict(zip(signal, df.loc[span, c])),\n",
    "                 **{'hand' : hand, f'{c}_dum' : 1}} for c in channels]\n",
    "        extra  = pd.concat([extra, pd.DataFrame(part)])\n",
    "\n",
    "    return extra\n",
    "\n",
    "### Pour récupérer les évènement relatifs à la survenue d'une action associcée aux mains\n",
    "def share_out(df : pd.DataFrame, event0 : list[int], event1 : list[int], size : int,\n",
    "              canals : list[str], expend : int = 0) -> pd.DataFrame :\n",
    "    hand0 = hand_out(df, event0, size, canals, 0, expend)\n",
    "    hand1 = hand_out(df, event1, size, canals, 1, expend)\n",
    "    res   = pd.concat([hand0, hand1])\n",
    "\n",
    "    res.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    return res\n",
    "\n",
    "###\n",
    "def full_event(data : pd.Series | list[float], tracks : list[list[int]]) -> list[float] :\n",
    "    return np.array(data)[tracks].flatten()\n",
    "\n",
    "### Coefficients du filtre Butterworth pour filtrage passe-bande\n",
    "def butter_bandpass(lowcut : float, highcut : float, fs : float, order : int = 4) \\\n",
    "        -> tuple[np.array, np.array] :\n",
    "    return signal.butter(order, 2 * np.array([lowcut, highcut]) / fs, btype = 'band')\n",
    "\n",
    "### Filtre passe-bande (avec les coefficients b et a issus de la décomposition de Butterworth)\n",
    "def bandpass_filter(data : pd.Series | pd.DataFrame, b : list[float], a : list[float]) -> np.array :\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "### Filtre Notch \n",
    "def notch_filter(data : list[float], freq : float, fs : float, window : int, order : int,\n",
    "                 ripple : float = None, filter_type : str = None) -> np.array :\n",
    "    b, a = signal.iirfilter(order, ((2 * freq) + np.array([-window, window])) / fs,\n",
    "                            rp = ripple, btype = 'bandstop', analog = False, ftype = filter_type)\n",
    "    \n",
    "    return signal.lfilter(b, a, data)\n",
    "\n",
    "### Calcul de l'énergie du signal dans une fenêtre glissante\n",
    "def signal_energy(data : list[float], window_size : int) -> np.array :\n",
    "    energy = [np.sum(data[i : i + window_size] ** 2) for i in range(len(data) - window_size)]\n",
    "\n",
    "    return np.pad(np.array(energy), (0, window_size), 'constant')\n",
    "\n",
    "###\n",
    "def moving_average(data : list[float], w : int = 3) -> list[float] :\n",
    "    res = data.cumsum() / w\n",
    "\n",
    "    return np.append(np.zeros(w), res[w: ] - res[: -w])\n",
    "\n",
    "### https://fr.wikipedia.org/wiki/Lissage_exponentiel\n",
    "def simple_exponential_smoothing(data : list, alpha : float = 1, s0 : float = None) -> list[float] :\n",
    "    res  = data[0] if s0 is None else s0\n",
    "    beta = 1 - alpha\n",
    "\n",
    "    for x in data : res.append(alpha * x + beta * res[-1])\n",
    "\n",
    "    return res\n",
    "\n",
    "###\n",
    "def simple_thresholding(data : list[float]) -> tuple[float, list] :\n",
    "    peak = np.max(np.abs(data))\n",
    "\n",
    "    return peak, data / peak\n",
    "\n",
    "### Sous fonction de run_slicer\n",
    "def run_aggregator(data : list[float]) -> np.array :\n",
    "    agg  = [data[0]]                 # On enlève le dernier sample\n",
    "    last = agg[-1] + 1               # Rajouté ici pour le calcul des différences.\n",
    "    \n",
    "    for i in data[1 : ] :\n",
    "        if i - last > 1 :\n",
    "            agg.append(last)\n",
    "            agg.append(i)\n",
    "\n",
    "        last = i\n",
    "\n",
    "    return np.append(agg, last)\n",
    "\n",
    "### Runs are separated by 100 missing values, encoded as the negative maximum values.\n",
    "### D'après la définition il y a 100 valeurs continue. Mais, on ne tiendra pas compte de cette information.\n",
    "def run_slicer(data : list[float], step : int = 100) -> np.array :\n",
    "    parts = np.where(abs(data) >= step)[0]\n",
    "\n",
    "    if len(parts) == 0 : return [range(0, len(data))]\n",
    "    \n",
    "    runs = run_aggregator(parts)\n",
    "    splt = zip(np.append(0, runs[1 :: 2] + 1), np.append(runs[0 :: 2], len(data)) - 1)\n",
    "\n",
    "    return [range(a, b) for a, b in splt]\n",
    "\n",
    "### Détection des pics positif et négatif dans un signal\n",
    "def find_peaks_pos(data : list[float], scope : int) -> tuple[list[int], list[int]] :\n",
    "    pos, _ = signal.find_peaks(data, distance = scope)\n",
    "    neg, _ = signal.find_peaks(data * -1, distance = scope)\n",
    "     \n",
    "    return pos, neg\n",
    "\n",
    "###\n",
    "def mne_from_raw(data : pd.DataFrame, channels : list[str] | str, sf : int) -> mne.io.RawArray :\n",
    "    info = mne.create_info(ch_names = channels, sfreq = sf, ch_types = 'eeg')\n",
    "    \n",
    "    return mne.io.RawArray(data.T * 1e-6, info);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de vitesse d'execution de difféentes implémentations\n",
    "@temps_execution\n",
    "def f2a(a, b) :\n",
    "    a[np.where(b == 0)]\n",
    "\n",
    "@temps_execution\n",
    "def f3a(a, b) :\n",
    "    [x for j, x in enumerate(a) if b[j] == 0]\n",
    "\n",
    "@temps_execution\n",
    "def f0(df, evt, b) :\n",
    "    for a in b : full_event(df[a], evt)\n",
    "\n",
    "@temps_execution\n",
    "def f2(df, evt, b) :\n",
    "    np.array([np.array(df[a])[evt] for a in b]).flatten()\n",
    "\n",
    "@temps_execution\n",
    "def f3(df, w) :\n",
    "    [np.sum(df[i : i + w] ** 2) for i in range(w)]\n",
    "\n",
    "f0(), f2(), f3(), f2a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ploting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### Visualiser le signal original et les bandes de fréquences filtrées\n",
    "def plot_wavelets(df : pd.DataFrame, coeffs : dict[str, tuple[float, float]], Channels : list[str],\n",
    "                  scope = list[int], label : str = '') -> None :\n",
    "    n       = len(Channels)\n",
    "    _, ax   = plt.subplots(nrows = 2, ncols = n, figsize = (n * 7, 3.6), sharex = 0)\n",
    "    x_ticks = df.loc[scope, Channels[0]].index\n",
    "    label   += \" - \" if label != '' else ''\n",
    "\n",
    "    for i, col in enumerate(Channels) :\n",
    "        view    = ax[0, i]\n",
    "        data    = df.loc[scope, col]\n",
    "        signals = {band : bandpass_filter(data, b, a) for band, (b, a) in coeffs.items()}\n",
    "\n",
    "        view.plot(data, label = 'Raw signal')\n",
    "        view.plot(pd.Series(signals[[*signals][0]], x_ticks), '--', c = 'maroon', label = 'Porteuse') # darkviolet indigo firebrick tomato darkturquoise\n",
    "        view.set_title(label + col)\n",
    "        view.legend(loc = 'upper right')\n",
    "        \n",
    "        view = ax[1, i]\n",
    "\n",
    "        for (band, signal) in reversed(signals.items()) :\n",
    "            view.plot(pd.Series(signal, x_ticks), label = f'{band}', c = np.random.rand(1, 3)[0])\n",
    "\n",
    "        view.legend(loc = 'upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show();\n",
    "\n",
    "###\n",
    "def plot_window(df : pd.DataFrame, columns : list | str, start : int = 0, size : int = None) -> None :\n",
    "    size : int = (df.shape[1] - start) if (size is None) else size\n",
    "    end  : int = start + size\n",
    "    \n",
    "    if type(columns) is list :\n",
    "        for c in columns :\n",
    "            if '+' in c :\n",
    "                plt.plot(df[[x.strip() for x in c.split('+')]][start : end].sum(axis = 1), label = c);\n",
    "            else :\n",
    "                plt.plot(df[c][start : end], label = c);\n",
    "    else :\n",
    "        plt.plot(df[columns][start : end], label = c);\n",
    "\n",
    "###\n",
    "def plot_psd(datas : list[pd.DataFrame], event_type : pd.DataFrame, rate : int,\n",
    "             Channels : list[str], titles : list[str] = None) -> None :\n",
    "    n = len(datas)\n",
    "    k = 1 << 9\n",
    "\n",
    "    fig, ax = plt.subplots(nrows = n, ncols = 3, figsize = (20, n * 2.5))\n",
    "    fig.tight_layout(pad = 3.5)\n",
    "\n",
    "    for i, df in enumerate(datas) :\n",
    "        view = ax[i, 0]\n",
    "        chap = (titles[i] if titles != None else '') \n",
    "        \n",
    "        view.set_title(chap)\n",
    "\n",
    "        for ch in Channels :\n",
    "            view.psd(df[ch], NFFT = k, Fs = rate, label = ch)\n",
    "\n",
    "        view.legend(loc = 'upper right');\n",
    "        \n",
    "        for j in range(2) :\n",
    "            view = ax[i, j + 1]\n",
    "            \n",
    "            view.set_title(f'{chap} - Main ({j})')\n",
    "\n",
    "            for ch in Channels :\n",
    "                view.psd(event_type.loc[i, f'E{j}_{ch}'], NFFT = k, Fs = rate, label = ch)\n",
    "                \n",
    "            view.legend(loc = 'upper right');\n",
    "\n",
    "    plt.show();\n",
    "\n",
    "###\n",
    "def subplot_signal(fig : plt.Axes, event0 : list[int], event1 : list[int], span : int,\n",
    "                   origin : float, width : int, height : int) :\n",
    "    mask  = .75\n",
    "\n",
    "    for i, ev in enumerate([event0, event1]) :\n",
    "        for x in ev :\n",
    "            fig.add_patch(Rectangle((x[0], -origin), width = width, height = height,\n",
    "                                    color = ['teal', 'salmon'][i], alpha = mask))   # '#1B4E88' '#793F22'\n",
    "    \n",
    "    fig.hlines(-origin, xmin = 0, xmax = span, colors = '#D03C01')\n",
    "    fig.hlines( origin, xmin = 0, xmax = span, colors = '#D03C01')\n",
    "\n",
    "###\n",
    "def plot_signal(data : pd.DataFrame, parts : list[tuple[int, int]], event0 : list[int],\n",
    "                event1 : list[int], channels : list[str], title : str = '') -> None :\n",
    "    k     = 2 if len(parts) > 1 else 1\n",
    "    _, ax = plt.subplots(nrows = 3 * k, figsize = (24, 6 * k))\n",
    "    pitch = event0[0][-1] - event0[0][0]\n",
    "\n",
    "    for i, col in enumerate(channels) :\n",
    "        j     = (i << 1) if len(parts) > 1 else i\n",
    "        df    = data[col]\n",
    "        seuil = df.quantile(q = .9975) * 2\n",
    "        xmax  = len(df)\n",
    "        view  = ax[j + 0]\n",
    "        h     = seuil * 2\n",
    "\n",
    "        peaks_pos, peaks_neg = find_peaks_pos(df, pitch)\n",
    "\n",
    "        view.plot(df, c = 'gray', label = col, zorder = -1)\n",
    "        view.plot(peaks_pos, df[peaks_pos], \"x\", color = 'purple')\n",
    "        view.plot(peaks_neg, df[peaks_neg], \"x\", color = 'goldenrod')\n",
    "        view.legend(loc = 'upper right')\n",
    "        subplot_signal(view, event0, event1, xmax, seuil, pitch, h)\n",
    "        \n",
    "        if len(parts) > 1 :\n",
    "            view = ax[j + 1]\n",
    "\n",
    "            for x in parts : view.plot(df[x], zorder = -1)   \n",
    "            \n",
    "            subplot_signal(view, event0, event1, xmax, seuil, pitch, h)\n",
    "\n",
    "    if title != '' : ax[0].set_title(title)\n",
    "\n",
    "    plt.show();\n",
    "\n",
    "###\n",
    "def spectrogram_from_EEG(data : list[float], Sampling_rate : int, prior_cut_off : int,\n",
    "                         later_cut_off : int, view : plt.axes = None) -> None :\n",
    "    f, t, Sxx = signal.spectrogram(data, fs = Sampling_rate)\n",
    "\n",
    "    k     = len(f) / f[-1]\n",
    "    scope = range(int(prior_cut_off * k), int(later_cut_off * k))\n",
    "\n",
    "    (plt if view is None else view).pcolormesh(t, f[scope], Sxx[scope], shading = 'gouraud')\n",
    "\n",
    "    # prior = \n",
    "    # later = \n",
    "    # (plt if view is None else view).pcolormesh(t, f[prior : later], Sxx[prior : later], shading = 'gouraud')\n",
    "    \n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.xlabel(\"Time (sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constantes\n",
    "\n",
    "# Fréquence d'échantillonnage - Hz (Nombre de valeur / sec)\n",
    "SAMPLE_RATE  = 250\n",
    "# Nombre d'échantillon consectutif (4\" . SAMPLE_RATE) 4 * \n",
    "SCOPE : int  = SAMPLE_RATE << 2\n",
    "# Temps additionel pour étendre le domaines d'étude.\n",
    "LAG : int    = SAMPLE_RATE >> 1\n",
    "# --------------------------------------------------\n",
    "EPOCH : int  = SCOPE + (LAG << 0)\n",
    "\n",
    "# Les bandes de fréquences d'intérêt\n",
    "eeg_bands    = {'Delta': (.1, 4), 'Theta': (4, 8), 'Alpha': (8, 13), 'Beta': (13, 30), 'Gamma': (30, 100)}\n",
    "# Correspondance pour la classification\n",
    "hands_event  = {0 : 'Left', 1 : 'Right'}\n",
    "# Deux enregistrements bipolaires + neutre\n",
    "eeg_Channels = ['C3', 'C4', 'Cz']\n",
    "# Trois enregistrements musculaires\n",
    "ecg_Channels = ['EOG:ch01', 'EOG:ch02', 'EOG:ch03']\n",
    "# Liste de tous les cannaux des dataframes\n",
    "all_channels = eeg_Channels + ecg_Channels\n",
    "# Coefficients pour filtres Butterworth numérique d'ordre N pour le filtrage passe-bande\n",
    "bands_coeff  = {band : butter_bandpass(low, high, SAMPLE_RATE) for band, (low, high) in eeg_bands.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target  = \"../data/data.zip\"\n",
    "scope   = range(1, 4)\n",
    "fics    = [f'B0{i}0{j}T.csv' for i in scope for j in range(1, 4)]\n",
    "notes   = [x.split('.')[0] for x in fics]\n",
    "headers = [f\"{i} . {t}\" for i, t in enumerate(notes)]\n",
    "\n",
    "df_train_csv = csv_in_zip(target, directory = 'train', files = fics)\n",
    "df_label_csv = csv_in_zip(target, directory = 'y_train_only', files = fics)\n",
    "\n",
    "count = range(len(df_train_csv))\n",
    "\n",
    "# df_train_pkl = pkl_in_zip(path, fichier_specifique = 'epoched_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in count :\n",
    "    display(headers[i], df_train_csv[i].describe()) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_event = []   # \n",
    "event0 = []         # Listes des évenements 0 \n",
    "event1 = []         # Listes des évènements 1\n",
    "tracks = []         # \n",
    "\n",
    "for i in count :\n",
    "    data = df_train_csv[i]\n",
    "    evts = df_label_csv[i]['EventType']\n",
    "    cuts = np.where(data['EventStart'] == 1)[0]\n",
    "    tout = np.array([range(x - LAG, x + EPOCH) for x in cuts])\n",
    "    evt0 = tout[np.where(evts == 0)]\n",
    "    evt1 = tout[np.where(evts == 1)]\n",
    "\n",
    "    # Extraction des informations \"recentré\" autours de l'apparition des évènements\n",
    "    signal_event.append({\n",
    "        **{f'E0_{col}': pd.Series(full_event(data[col], evt0)) for col in eeg_Channels},\n",
    "        **{f'E1_{col}': pd.Series(full_event(data[col], evt1)) for col in eeg_Channels},\n",
    "        })\n",
    "    tracks.append(run_slicer(data['C3'], 75))\n",
    "    event0.append(evt0) \n",
    "    event1.append(evt1)\n",
    "\n",
    "event_over = pd.DataFrame(signal_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(event_over)\n",
    "\n",
    "for i in count :\n",
    "    display(headers[i], pd.DataFrame([event_over.loc[i, c].describe() for c in columns], columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sktime.datasets import load_italy_power_demand\n",
    "\n",
    "# X, y = load_italy_power_demand()\n",
    "\n",
    "# display(X)\n",
    "# X.iloc[0, 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_psd(df_train_csv, event_over, rate = SAMPLE_RATE, Channels = eeg_Channels, titles = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fics)) : #  [2 :: 3]\n",
    "    plot_signal(df_train_csv[i], tracks[i], event0[i], event1[i], channels = eeg_Channels, title = headers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Test de décomposition des signaux en bandes de fréquences spécifiques compatibles avec les répartitions usuelles\n",
    "# dans le domaine des EEG ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']\n",
    "###\n",
    "for it in range(1, 8) :\n",
    "    for i in range(3) :\n",
    "        plot_wavelets(df_train_csv[it], bands_coeff, eeg_Channels, event1[it][i], headers[it] + f\" ({i})\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_csv = df_train_csv[0][eeg_Channels]\n",
    "info    = mne.create_info(ch_names = eeg_Channels, sfreq = SAMPLE_RATE, ch_types = 'eeg')\n",
    "raw_mne = mne.io.RawArray(raw_csv.T * 1e-6, info)\n",
    "\n",
    "tmin, tmax = -0., 1\n",
    "events  = mne.find_events(raw_mne, stim_channel = 'C3')\n",
    "# event_id = dict(C3 = 1, aud_r = 2, vis_l = 3, vis_r = 4)\n",
    "\n",
    "events = np.where(df_train_csv[0]['EventStart'] == 1)[0]\n",
    "\n",
    "# raw = mne.io.Raw(raw_mne, preload = True)\n",
    "# raw.filter(2, None, method = 'iir')           # replace baselining with high-pass\n",
    "# events = mne.read_events(event_fname)\n",
    "\n",
    "# raw.info['bads'] = ['MEG 2443']  # set bad channels\n",
    "# picks = mne.pick_types(info, meg = 'grad', eeg = True, eog = False, exclude = 'bads')\n",
    "# Read epochs\n",
    "epochs = mne.Epochs(raw_mne, np.array([events, events, events]).T, None, tmin, tmax, proj = False,\n",
    "                    picks = None, baseline = None, preload = True, verbose = False) # event_id picks\n",
    "\n",
    "# labels = epochs.events[::5, -1]\n",
    "\n",
    "# events\n",
    "\n",
    "# raw_mne.plot();\n",
    "\n",
    "# raw_mne['C3'][0][0], len(df_train_csv[2]['Cz'])\n",
    "\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = pd.concat([share_out(train, h0, h1, SCOPE, eeg_Channels) for train, h0, h1 in zip(df_train_csv, event0, event1)])\n",
    "\n",
    "extra.reset_index(drop = True, inplace = True)\n",
    "extra.fillna(0, inplace = True)\n",
    "\n",
    "extra\n",
    "\n",
    "# res = share_out(df_train_csv[0], hands0[0], hands1[0], scope, eeg_canals)\n",
    "\n",
    "# res.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = extra.drop(columns = ['data_split', 'hand', 'C3_dum', 'C4_dum', 'Cz_dum'])\n",
    "y    = extra['hand']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, y, test_size = .2)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train, y_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-plus proches voisins\n",
    "clf1 = neighbors.KNeighborsClassifier()\n",
    "# SVM (support vector machine)[, 'auto']\n",
    "clf2 = svm.SVC(gamma = 'scale')\n",
    "# RandomForest\n",
    "clf3 = ensemble.RandomForestClassifier(n_jobs = -1)\n",
    "\n",
    "Voting_clf = VotingClassifier(estimators = [('knn', clf1), ('svm', clf2), ('rf', clf3)], voting = 'hard')\n",
    "# cv3        = model_selection.KFold(n_splits = 3, random_state = 42, shuffle = True)\n",
    "\n",
    "for clf in [clf1, clf2, clf3] :\n",
    "    print(f\"● {clf} :\")\n",
    "\n",
    "    scores : dict = model_selection.cross_validate(clf, X_train, y_train, cv = 3, scoring = ['accuracy'])\n",
    "    \n",
    "    # r = abs(scores['test_neg_mean_squared_error'])\n",
    "    # print(f\"  - Mean square ;{r.mean(): .3} (±{r.std(): .2})\")\n",
    "    r = scores['test_accuracy']\n",
    "    print(f\"  - Accuracy    ;{r.mean(): .3} (±{r.std(): .2})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # K-plus proches voisins\n",
    "    'knn__n_neighbors' : range(2, 5),\n",
    "    # SVM\n",
    "    'svm__C'      : [0.1, 1, 5],\n",
    "    'svm__kernel' : ['linear', 'sigmoid', 'rbf'],\n",
    "    # RandomForest\n",
    "    # 'rf__max_features'      : ['sqrt', 'log2', None],\n",
    "    # 'rf__min_samples_split' : range(2, 32, 2),\n",
    "    # , ('rf', clf3), ('rf', clf3)\n",
    "    'estimators': [[('knn', clf1), ('svm', clf2)], [('knn', clf1), ('svm', clf2)]] \n",
    "    }\n",
    "\n",
    "grid = model_selection.GridSearchCV(estimator = Voting_clf, param_grid = params, cv = 5) \\\n",
    "    .fit(X_train_scaled, y_train)\n",
    "\n",
    "# parametres = {'max_features' : ['log2', 'sqrt', None], 'min_samples_split' : range(2, 32, 2)}\n",
    "\n",
    "# vclf = model_selection.GridSearchCV(estimator = clf3, param_grid = parametres, cv = 3) \\\n",
    "#     .fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "print('score train :', grid.score(X_train_scaled, y_train))\n",
    "print('score test :', grid.score(X_test_scaled, y_test))\n",
    "\n",
    "# print(vclf.best_estimator_, vclf.best_params_)\n",
    "# print(vclf.best_score_)\n",
    "\n",
    "# print('score train :', grid.score(X_train_scaled, y_train), vclf.score(X_train_scaled, y_train))\n",
    "# print('score test :', grid.score(X_test_scaled, y_test), vclf.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cpy, event_start = fancy_df(df_train_csv, df_label_csv['EventType'], hands_event, SCOPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize = (24, 5), sharey = True)\n",
    "sig = .05\n",
    "\n",
    "axes.plot(df_train_csv['C3'])\n",
    "\n",
    "for p in event_start :\n",
    "    axes.axvspan(p[0] - SCOPE / 2, p[0] + 1.5 * SCOPE, facecolor = 'orangered', alpha = .5)\n",
    "\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos    = 16\n",
    "start  = event_start[pos][0]\n",
    "scope  = start + SCOPE\n",
    "data   = df_train_cpy['C3_4'][start : scope]\n",
    "smooth = data.copy()\n",
    "n      = 5\n",
    "alpha  = 1 / 3\n",
    "dec    = int(n / alpha)\n",
    "\n",
    "plt.figure(figsize = (24, 5))\n",
    "plot_window(df_train_csv, ['C3', 'C4', 'C3 + C4'], start, SCOPE)\n",
    "\n",
    "# Lissage des hautes fréquences\n",
    "for _ in range(n) :\n",
    "    smooth = simple_exponential_smoothing(smooth, alpha, 0)\n",
    "\n",
    "smooth = pd.Series(index = range(start, scope + n - dec), data = smooth[dec :])\n",
    "\n",
    "# plt.plot(raw - smooth, label = hands[event_start[pos][1]])\n",
    "plt.plot(smooth, '--', label = hands_event[event_start[pos][1]])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###\n",
    "# def eeg_spliting(signal : list, wavelet : str = 'db4', level : int = 5) :\n",
    "#     coeffs = pywt.wavedec(signal, wavelet, level)\n",
    "    \n",
    "#     # Visualiser le signal original et les coefficients\n",
    "#     _, ax = plt.subplots(len(coeffs) + 1, 1, figsize = (12, 8))\n",
    "    \n",
    "#     ax[0].plot(signal, label =' Signal EEG synthétique')\n",
    "#     ax[0].legend(loc = 'upper right')\n",
    "\n",
    "#     for i, coeff in enumerate(coeffs) :\n",
    "#         ax[i + 1].plot(coeff, label = f'Coefficients niveau {i}')\n",
    "#         ax[i + 1].legend(loc = 'upper right')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(1, 3, figsize = (20, 3), sharey = True)\n",
    "# spectrogram_fromEEG(raw, SAMPLE_RATE, 10, 50, axs = ax[0])\n",
    "# spectrogram_fromEEG(smooth, SAMPLE_RATE, 10, 50, axs = ax[1])\n",
    "# spectrogram_fromEEG(raw - smooth, SAMPLE_RATE, 10, 50, axs = ax[2])\n",
    "# plt.show();\n",
    "\n",
    "# sig_C3 = df_train_csv['C3']'Cz', \n",
    "# sig_C4 = df_train_csv['C4'][START : START + SCOPE]\n",
    "# sig_cz = df_train_csv['Cz'][START : START + SCOPE]\n",
    "\n",
    "# plt.figure(figsize = (20, 5))\n",
    "# plt.plot(sig_C3, color = 'cornflowerblue')\n",
    "# plt.plot(sig_cz, color = 'orangered')\n",
    "# plt.plot(sig_C4, color = 'green')\n",
    "\n",
    "# plt.figure(figsize = (20, 5))\n",
    "# plt.plot(stats.zscore(sig_C3), color = 'cornflowerblue')\n",
    "# plt.plot(stats.zscore(sig_cz), color = 'orangered')\n",
    "# plt.plot(stats.zscore(sig_C4), color = 'green')\n",
    "# plt.plot(stats.zscore(sig_C3 + sig_C4), color = 'magenta')\n",
    "# plt.show();\n",
    "\n",
    "\"\"\"\n",
    "rw      = df_train_csv['C3'] # df_train_pkl['C3'][0]\n",
    "rz      = rw.copy()\n",
    "ro      = rw.copy()\n",
    "\n",
    "# for _ in range(n) :\n",
    "#     rz = Simple_exponential_smoothing(rz, alpha, 0)\n",
    "#     ro = Simple_exponential_smoothing(ro, alpha)\n",
    "\n",
    "recal = \n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax1 = fig.add_axes()\n",
    "# fig.add_gridspec(x = [x[0] for x in event_start], y = np.zeros(120))\n",
    "# ax.grid(axis = \"x\")\n",
    "\n",
    "# plt.xticks(y_pos, bars, color='orange', rotation=45, fontweight='bold', fontsize='17', horizontalalignment='right')\n",
    "# plt.tick_params(axis = 'x', colors = 'red', direction = 'out', length = 13) #, width =3\n",
    "\n",
    "plt.plot(stats.zscore(df_train_csv['C3']), color = 'cornflowerblue')\n",
    "plt.plot(stats.zscore(df_train_csv['Cz']))\n",
    "plt.plot(stats.zscore(df_train_csv['C4']))\n",
    "# plt.plot(stats.zscore(rz[recal: ]), 'm')\n",
    "# plt.plot(stats.zscore(ro[recal: ]), '--', color = 'blue')\n",
    "# \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
