{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/nadosh/my-project-bci-2008\n",
    "\n",
    "import sys, os #, math, time\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "from src.thot.sesh import *\n",
    "from src.thot.catch_features import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "from sklearn import discriminant_analysis, linear_model, ensemble, svm\n",
    "import re\n",
    "\n",
    "# Helper class to train sklearn gridsearchcv models & report metrics\n",
    "class gridsearchcv_model:\n",
    "#   model: saved model\n",
    "#   name: name for model\n",
    "#   train, val: object with {name, predictions, mse OR accuracy} \n",
    "\n",
    "    def __init__(self, model, X_train, Y_train, X_val, Y_val, parameter_matrix = {}, is_classification=False, cv = 4):\n",
    "        self.is_classification = is_classification\n",
    "        self.train_model(model, X_train, Y_train, X_val, Y_val, parameter_matrix, cv)\n",
    "        \n",
    "    # Trains model using a training set and predicts a validation set\n",
    "    def train_model(self, model, X_train, Y_train, X_val, Y_val, parameter_matrix = {}, cv = 4):\n",
    "        if self.is_classification:\n",
    "            ml_model = model_selection.GridSearchCV(model, parameter_matrix, cv=cv, scoring='f1')\n",
    "        else:\n",
    "            ml_model = model_selection.GridSearchCV(model, parameter_matrix, cv=cv, scoring='neg_mean_squared_error')\n",
    "        \n",
    "        ml_model.fit(X_train, Y_train)\n",
    "        \n",
    "        self.model = ml_model.best_estimator_\n",
    "        self.name = re.compile(\"(.*?)\\s*\\(\").match(str(self.model)).group(1)\n",
    "        \n",
    "        self.train = {'name': 'train'}\n",
    "        self.val = {'name': 'val'}\n",
    "        \n",
    "        self.calculate_error(self.train, X_train, Y_train, self.train['name'])\n",
    "        self.calculate_error(self.val, X_val, Y_val, self.val['name'])\n",
    "        \n",
    "        return ml_model\n",
    "    \n",
    "    def calculate_error(self, var, X_set, Y_set, name):\n",
    "        var['name'] = name\n",
    "        var['predictions'] = self.model.predict(X_set)\n",
    "        \n",
    "        if self.is_classification:\n",
    "            var['accuracy'] = metrics.f1_score(Y_set, var['predictions'])\n",
    "        else:\n",
    "            var['mse'] = metrics.mean_squared_error(Y_set, var['predictions'])\n",
    "        \n",
    "        self.print_error(var)\n",
    "        \n",
    "    # Prints error metrics\n",
    "    def print_error(self, var):\n",
    "        print(f\"{self.name} ({var['name']})\")\n",
    "        \n",
    "        if self.is_classification:\n",
    "            print(f\"Accuracy: {var['accuracy']:.2%}\")\n",
    "        else:\n",
    "            print(f\"MSE: {var['mse']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data into dataframes\n",
    "\n",
    "path              = '../data/data.zip'\n",
    "df_train_original = pickle_in_zip(path, \"epoched_train.pkl\")\n",
    "df_test           = pickle_in_zip(path, \"epoched_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column 'pid' which is the patient ID 1 through 9\n",
    "df_train_original['pid'] = [int(df_train_original['patient_id'][x][2]) for x in range(len(df_train_original))]\n",
    "df_test['pid'] = [int(df_test['patient_id'][x][2]) for x in range(len(df_test))]\n",
    "\n",
    "# Create column 'trial_id' which is the trial 1 through 3\n",
    "df_train_original['trial_id'] = [int(df_train_original['patient_id'][x][-2]) for x in range(len(df_train_original))]\n",
    "df_test['trial_id'] = [int(df_test['patient_id'][x][-2]) for x in range(len(df_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use trials 1&2 for training, trial 3 for validation (mirrors process to create Kaggle test set)\n",
    "df_train = df_train_original[df_train_original['trial_id'] != 3]\n",
    "df_train = df_train.reindex(np.random.permutation(df_train.index)).reset_index(drop = True)\n",
    "\n",
    "df_val = df_train_original[df_train_original['trial_id'] == 3]\n",
    "df_val = df_val.reindex(np.random.permutation(df_val.index)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training across all subjects\n",
    "y_train = df_train[\"event_type\"].values.astype(float)\n",
    "y_val   = df_val[\"event_type\"].values.astype(float)\n",
    "\n",
    "X_train = df_train.drop(columns = [\"patient_id\", \"start_time\", \"event_type\", \"pid\", \"trial_id\"])\n",
    "X_val   = df_val  .drop(columns = [\"patient_id\", \"start_time\", \"event_type\", \"pid\", \"trial_id\"])\n",
    "X_test  = df_test .drop(columns = [\"patient_id\", \"start_time\", \"pid\", \"trial_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_nn  = np.array(list(X_train.apply(lambda x : np.concatenate(x), axis = 1)))\n",
    "x_val_nn    = np.array(X_val.apply  (lambda x : np.concatenate(x), axis = 1).values.tolist())\n",
    "x_test_nn   = np.array(X_test.apply (lambda x : np.concatenate(x), axis = 1).values.tolist())\n",
    "\n",
    "v1 = np.array([np.concatenate(x) for x in X_train.values])\n",
    "\n",
    "v1\n",
    "\n",
    "# display(x_train_nn)\n",
    "# print(x_train_nn.shape)\n",
    "\n",
    "# sum(sum(v1 - x_train_nn))\n",
    "\n",
    "# np.concatenate(list(X_train.values), axis = 1)\n",
    "\n",
    "# np.shape(np.array([*X_train.values]))\n",
    "\n",
    "# [ for x in ] # X_train.apply(lambda x : np.concatenate(x), axis = 1).values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "param_matrix    = {}\n",
    "logistic_model  = gridsearchcv_model(linear_model.LogisticRegression(), x_train_nn, y_train, x_val_nn, y_val,\n",
    "                                    parameter_matrix=param_matrix, is_classification=True)\n",
    "rf_model        = gridsearchcv_model(ensemble.RandomForestClassifier(), x_train_nn, y_train, x_val_nn, y_val,\n",
    "                              parameter_matrix=param_matrix, is_classification=True)\n",
    "svm_model       = gridsearchcv_model(svm.SVC(), x_train_nn, y_train, x_val_nn, y_val,\n",
    "                                     parameter_matrix=param_matrix, is_classification=True)\n",
    "lda_model       = gridsearchcv_model(discriminant_analysis.LinearDiscriminantAnalysis(), x_train_nn, y_train,\n",
    "                                     x_val_nn, y_val, parameter_matrix=param_matrix, is_classification=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
